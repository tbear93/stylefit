# 📘 StyleFit AI 측정 엔진: 팀원들을 위한 가이드 (v3.12.1)

본 문서는 StyleFit 엔진이 사진 한 장으로 어떻게 실제 신체 치수를 도출하는지, 그 **5단계 메커니즘**을 설명합니다.

---

### 1단계: 랜드마크(Landmark) 추출
**"AI가 몸에서 기준점을 찍는 과정입니다."**

* **수행**: MediaPipe AI가 이미지 내에서 33개의 주요 관절 포인트를 찾습니다.
* **주요 포인트**: 
    * **어깨**: 11번(좌), 12번(우)
    * **골반/허리**: 23번(좌), 24번(우)
    * **전신**: 0번(코), 27/28번(양쪽 발목)
* **특징**: 이 단계에서 데이터는 실제 cm가 아닌 이미지상의 **좌표(x, y 픽셀)** 값입니다.

---

### 2단계: 픽셀(px) → 센티미터(cm) 환산
**"사진 속의 1픽셀이 실제로는 몇 cm인지 계산합니다."**

* **한계**: AI는 정수리를 인식하지 못하고 '코(0번)'까지만 찍습니다.
* **해결(7% 법칙)**: 인체 해부학 통계상 **정수리부터 코까지는 전체 키의 약 7%**입니다.
* **계산**: 
    * 사용자의 키가 180cm라면, '코에서 발바닥'까지를 **167.4cm** ($180 \times 0.93$)로 간주합니다.
    * **공식**: $167.4cm \div \text{코-발목의 픽셀 거리} = 1\text{픽셀당 cm (cm/px)}$
    * *이 비율이 나와야 사진 속 모든 선의 길이를 cm로 바꿀 수 있습니다.*

---

### 3단계: 부위별 측정과 보정(Offset)
**"뼈의 위치와 실제 몸의 부피 차이를 메웁니다."**

AI가 찍은 '관절(뼈)' 위치는 실제 '신체 표면'과 다르기 때문에 **마법의 보정값**을 더합니다.

| 부위 | 측정 방식 | 보정값 (Offset) | 보정 근거 |
| :--- | :--- | :--- | :--- |
| **어깨 너비** | 11번-12번 픽셀 거리 | **+1.5cm** | 뼈 끝점보다 바깥쪽인 **어깨 근육(삼각근)** 두께 반영 |
| **허리 너비** | 23번-24번 픽셀 거리 | **+4.0cm** | 안쪽 골반 뼈에서 **옆구리 살집**까지의 두께 반영 |

---

### 4단계: 입체 둘레(Circumference) 추정
**"평면 사진(2D)을 바탕으로 입체(3D) 둘레를 뽑아냅니다."**

수만 명의 한국인 데이터를 분석한 **Size Korea(국가공인 표준)** 통계 계수를 사용합니다.

* **어깨 둘레**: 측정 너비 $\times$ **2.3** (상체는 앞뒤가 비교적 납작함)
* **허리 둘레**: 측정 너비 $\times$ **2.7** (하체는 전후 두께가 있는 편)
* **결과**: 이 과정을 통해 실제 바지나 상의 사이즈(inch)와 대조 가능한 데이터가 완성됩니다.

---

### 5단계: 지능형 허리라인(Waistline) 튜닝
**"사용자가 직접 이미지 속 실제 허리 위치를 특정합니다."**

AI가 찍은 골반점은 실제 바지 허리선보다 낮습니다. 이를 슬라이더로 보정하면 두 가지가 연동됩니다.

1. **너비 연동**: 위로 올라갈수록 몸이 잘록해지는 인체 구조를 반영하여 **허리 너비가 실시간 감소**합니다.
2. **기장 연동**: 허리선이 올라간 만큼 **상체 기장은 짧아지고, 다리 길이는 길어지며** 실제 비율을 찾아갑니다.

---

### 💡 팀원들을 위한 요약
우리 StyleFit 엔진은 **AI의 관절 트래킹** 기술에 **해부학적 통계(7%)**와 **의류 실무 보정값**을 결합하여, 단순한 사진 분석을 넘어선 **'진짜 의류 피팅 데이터'**를 만드는 시스템입니다.
